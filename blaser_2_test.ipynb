{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaf69fc4",
   "metadata": {},
   "source": [
    "# BLASER 2.0: Testing Sentence Similarity\n",
    "\n",
    "This notebook demonstrates how to use BLASER 2.0 for predicting sentence similarity using the SONAR embedding space. BLASER 2.0 is a family of models for automatic evaluation of machine translation quality based on SONAR embeddings.\n",
    "\n",
    "There are two main models available:\n",
    "- **BLASER 2.0 QE (Quality Estimation)**: Predicts similarity between source text and translation without requiring reference translations\n",
    "- **BLASER 2.0 Ref**: Predicts similarity using source, translation, and reference translation\n",
    "\n",
    "Both models are based on the [SONAR](https://github.com/facebookresearch/SONAR) (Sentence-level multimOdal and laNguage-Agnostic Representations) framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb6a5f6",
   "metadata": {},
   "source": [
    "## Installing Required Packages with UV\n",
    "\n",
    "We'll use `uv` to create a virtual environment and install the necessary packages. UV is a fast Python package installer and resolver, which makes dependency management more efficient.\n",
    "\n",
    "SONAR requires specific versions of fairseq2 that match the PyTorch and CUDA versions. If you don't have `uv` installed, you can install it first with:\n",
    "```bash\n",
    "curl -sSf https://install.python-uv.org | python3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb70c7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPython \u001b[36m3.10.18\u001b[39m\n",
      "Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
      "Activate with: \u001b[32msource .venv/bin/activate\u001b[39m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m147 packages\u001b[0m \u001b[2min 38ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 590ms\u001b[0m\u001b[0m                                              \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m147 packages\u001b[0m \u001b[2min 250ms\u001b[0m\u001b[0m                             \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1margon2-cffi\u001b[0m\u001b[2m==25.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1margon2-cffi-bindings\u001b[0m\u001b[2m==21.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1marrow\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1masttokens\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1masync-lru\u001b[0m\u001b[2m==2.0.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mattrs\u001b[0m\u001b[2m==25.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbabel\u001b[0m\u001b[2m==2.17.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbeautifulsoup4\u001b[0m\u001b[2m==4.13.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mblaser-testing\u001b[0m\u001b[2m==0.1.0 (from file:///home/ec2-user/Projects/blaser_experiment)\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbleach\u001b[0m\u001b[2m==6.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mblobfile\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.4.26\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcffi\u001b[0m\u001b[2m==1.17.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcolorama\u001b[0m\u001b[2m==0.4.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcomm\u001b[0m\u001b[2m==0.2.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdebugpy\u001b[0m\u001b[2m==1.8.14\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdecorator\u001b[0m\u001b[2m==5.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdefusedxml\u001b[0m\u001b[2m==0.7.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1meditdistance\u001b[0m\u001b[2m==0.8.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mexceptiongroup\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mexecuting\u001b[0m\u001b[2m==2.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfairseq2\u001b[0m\u001b[2m==0.4.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfairseq2n\u001b[0m\u001b[2m==0.4.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfastjsonschema\u001b[0m\u001b[2m==2.21.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.18.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfqdn\u001b[0m\u001b[2m==1.5.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.5.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mh11\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpcore\u001b[0m\u001b[2m==1.0.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.28.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mimportlib-metadata\u001b[0m\u001b[2m==7.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mimportlib-resources\u001b[0m\u001b[2m==6.5.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mipykernel\u001b[0m\u001b[2m==6.29.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mipython\u001b[0m\u001b[2m==8.37.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mipywidgets\u001b[0m\u001b[2m==8.1.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1misoduration\u001b[0m\u001b[2m==20.11.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjedi\u001b[0m\u001b[2m==0.19.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjinja2\u001b[0m\u001b[2m==3.1.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjson5\u001b[0m\u001b[2m==0.12.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonpointer\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonschema\u001b[0m\u001b[2m==4.24.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonschema-specifications\u001b[0m\u001b[2m==2025.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjupyter\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjupyter-client\u001b[0m\u001b[2m==8.6.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjupyter-console\u001b[0m\u001b[2m==6.6.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjupyter-core\u001b[0m\u001b[2m==5.8.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjupyter-events\u001b[0m\u001b[2m==0.12.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjupyter-lsp\u001b[0m\u001b[2m==2.2.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjupyter-server\u001b[0m\u001b[2m==2.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjupyter-server-terminals\u001b[0m\u001b[2m==0.5.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjupyterlab\u001b[0m\u001b[2m==4.4.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjupyterlab-pygments\u001b[0m\u001b[2m==0.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjupyterlab-server\u001b[0m\u001b[2m==2.27.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjupyterlab-widgets\u001b[0m\u001b[2m==3.0.15\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlxml\u001b[0m\u001b[2m==5.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkdown-it-py\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmatplotlib-inline\u001b[0m\u001b[2m==0.1.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmdurl\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmistune\u001b[0m\u001b[2m==3.1.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmpmath\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmypy-extensions\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnbclient\u001b[0m\u001b[2m==0.10.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnbconvert\u001b[0m\u001b[2m==7.16.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnbformat\u001b[0m\u001b[2m==5.10.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnest-asyncio\u001b[0m\u001b[2m==1.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnetworkx\u001b[0m\u001b[2m==3.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnotebook\u001b[0m\u001b[2m==7.4.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnotebook-shim\u001b[0m\u001b[2m==0.2.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.4.5.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.1.0.70\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.2.1.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.5.147\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.6.1.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.3.1.170\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.6.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.21.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1moverrides\u001b[0m\u001b[2m==7.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==24.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpandocfilters\u001b[0m\u001b[2m==1.5.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mparso\u001b[0m\u001b[2m==0.8.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpexpect\u001b[0m\u001b[2m==4.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mplatformdirs\u001b[0m\u001b[2m==4.3.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mportalocker\u001b[0m\u001b[2m==3.1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mprometheus-client\u001b[0m\u001b[2m==0.22.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mprompt-toolkit\u001b[0m\u001b[2m==3.0.51\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpsutil\u001b[0m\u001b[2m==5.9.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mptyprocess\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpure-eval\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpycparser\u001b[0m\u001b[2m==2.22\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpycryptodomex\u001b[0m\u001b[2m==3.23.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-dateutil\u001b[0m\u001b[2m==2.9.0.post0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-json-logger\u001b[0m\u001b[2m==3.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyyaml\u001b[0m\u001b[2m==6.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==26.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mreferencing\u001b[0m\u001b[2m==0.36.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mregex\u001b[0m\u001b[2m==2024.11.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrfc3339-validator\u001b[0m\u001b[2m==0.1.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrfc3986-validator\u001b[0m\u001b[2m==0.1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrich\u001b[0m\u001b[2m==13.9.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrpds-py\u001b[0m\u001b[2m==0.25.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msacrebleu\u001b[0m\u001b[2m==2.5.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msend2trash\u001b[0m\u001b[2m==1.8.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==80.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msix\u001b[0m\u001b[2m==1.17.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msniffio\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msonar-space\u001b[0m\u001b[2m==0.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msoundfile\u001b[0m\u001b[2m==0.13.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msoupsieve\u001b[0m\u001b[2m==2.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msox\u001b[0m\u001b[2m==1.5.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mstack-data\u001b[0m\u001b[2m==0.6.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.13.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtabulate\u001b[0m\u001b[2m==0.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtbb\u001b[0m\u001b[2m==2022.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtcmlib\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mterminado\u001b[0m\u001b[2m==0.18.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtiktoken\u001b[0m\u001b[2m==0.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtinycss2\u001b[0m\u001b[2m==1.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtomli\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorchaudio\u001b[0m\u001b[2m==2.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorcheval\u001b[0m\u001b[2m==0.0.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtornado\u001b[0m\u001b[2m==6.5.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtraitlets\u001b[0m\u001b[2m==5.14.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtypes-python-dateutil\u001b[0m\u001b[2m==2.9.0.20250516\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.14.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1muri-template\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwcwidth\u001b[0m\u001b[2m==0.2.13\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwebcolors\u001b[0m\u001b[2m==24.11.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwebencodings\u001b[0m\u001b[2m==0.5.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwebsocket-client\u001b[0m\u001b[2m==1.8.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwidgetsnbextension\u001b[0m\u001b[2m==4.0.14\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mzipp\u001b[0m\u001b[2m==3.23.0\u001b[0m\n",
      "uv 0.7.12\n"
     ]
    }
   ],
   "source": [
    "# Create and activate environment with uv using pyproject.toml\n",
    "!uv venv .venv\n",
    "!source .venv/bin/activate\n",
    "\n",
    "# Install the project and its dependencies from pyproject.toml\n",
    "!uv pip install -e .\n",
    "\n",
    "# Check if UV installation was successful\n",
    "!uv --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed38e84",
   "metadata": {},
   "source": [
    "## Installing System Dependencies\n",
    "\n",
    "Before installing fairseq2, we need to install the libsndfile system dependency, which is required for audio processing functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c759ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last metadata expiration check: 0:30:32 ago on Wed Jun 11 16:59:58 2025.\n",
      "Dependencies resolved.\n",
      "================================================================================\n",
      " Package         Arch        Version                     Repository        Size\n",
      "================================================================================\n",
      "Installing:\n",
      " \u001b[1m\u001b[32mlibsndfile     \u001b[m x86_64      1.2.2-3.amzn2023.0.3        amazonlinux      225 k\n",
      "Installing dependencies:\n",
      " \u001b[1m\u001b[32mflac-libs      \u001b[m x86_64      1.3.4-1.amzn2023.0.2        amazonlinux      234 k\n",
      " \u001b[1m\u001b[32mgsm            \u001b[m x86_64      1.0.19-5.amzn2023.0.3       amazonlinux       39 k\n",
      " \u001b[1m\u001b[32mlibogg         \u001b[m x86_64      2:1.3.4-4.amzn2023.0.2      amazonlinux       34 k\n",
      " \u001b[1m\u001b[32mlibvorbis      \u001b[m x86_64      1:1.3.7-3.amzn2023.0.2      amazonlinux      206 k\n",
      " \u001b[1m\u001b[32mopus           \u001b[m x86_64      1.3.1-8.amzn2023.0.3        amazonlinux      225 k\n",
      "\n",
      "Transaction Summary\n",
      "================================================================================\n",
      "Install  6 Packages\n",
      "\n",
      "Total download size: 962 k\n",
      "Installed size: 2.5 M\n",
      "Downloading Packages:\n",
      "(1/6): libogg-1.3.4-4.amzn2023.0.2.x86_64.rpm   1.1 MB/s |  34 kB     00:00    \n",
      "(2/6): gsm-1.0.19-5.amzn2023.0.3.x86_64.rpm     1.1 MB/s |  39 kB     00:00    \n",
      "(3/6): flac-libs-1.3.4-1.amzn2023.0.2.x86_64.rp 6.0 MB/s | 234 kB     00:00    \n",
      "(4/6): libsndfile-1.2.2-3.amzn2023.0.3.x86_64.r 8.3 MB/s | 225 kB     00:00    \n",
      "(5/6): libvorbis-1.3.7-3.amzn2023.0.2.x86_64.rp 7.0 MB/s | 206 kB     00:00    \n",
      "(6/6): opus-1.3.1-8.amzn2023.0.3.x86_64.rpm     7.6 MB/s | 225 kB     00:00    \n",
      "--------------------------------------------------------------------------------\n",
      "Total                                            10 MB/s | 962 kB     00:00     \n",
      "Running transaction check\n",
      "Transaction check succeeded.\n",
      "Running transaction test\n",
      "Transaction test succeeded.\n",
      "Running transaction\n",
      "  Preparing        :                                                        1/1 \n",
      "  Installing       : libogg-2:1.3.4-4.amzn2023.0.2.x86_64                   1/6 \n",
      "  Installing       : flac-libs-1.3.4-1.amzn2023.0.2.x86_64                  2/6 \n",
      "  Installing       : libvorbis-1:1.3.7-3.amzn2023.0.2.x86_64                3/6 \n",
      "  Installing       : opus-1.3.1-8.amzn2023.0.3.x86_64                       4/6 \n",
      "  Installing       : gsm-1.0.19-5.amzn2023.0.3.x86_64                       5/6 \n",
      "  Installing       : libsndfile-1.2.2-3.amzn2023.0.3.x86_64                 6/6 \n",
      "  Running scriptlet: libsndfile-1.2.2-3.amzn2023.0.3.x86_64                 6/6 \n",
      "  Verifying        : flac-libs-1.3.4-1.amzn2023.0.2.x86_64                  1/6 \n",
      "  Verifying        : gsm-1.0.19-5.amzn2023.0.3.x86_64                       2/6 \n",
      "  Verifying        : libogg-2:1.3.4-4.amzn2023.0.2.x86_64                   3/6 \n",
      "  Verifying        : libsndfile-1.2.2-3.amzn2023.0.3.x86_64                 4/6 \n",
      "  Verifying        : libvorbis-1:1.3.7-3.amzn2023.0.2.x86_64                5/6 \n",
      "  Verifying        : opus-1.3.1-8.amzn2023.0.3.x86_64                       6/6 \n",
      "================================================================================\n",
      "WARNING:\n",
      "  A newer release of \"Amazon Linux\" is available.\n",
      "\n",
      "  Available Versions:\n",
      "\n",
      "  Version 2023.7.20250527:\n",
      "    Run the following command to upgrade to 2023.7.20250527:\n",
      "\n",
      "      dnf upgrade --releasever=2023.7.20250527\n",
      "\n",
      "    Release notes:\n",
      "     https://docs.aws.amazon.com/linux/al2023/release-notes/relnotes-2023.7.20250527.html\n",
      "\n",
      "  Version 2023.7.20250609:\n",
      "    Run the following command to upgrade to 2023.7.20250609:\n",
      "\n",
      "      dnf upgrade --releasever=2023.7.20250609\n",
      "\n",
      "    Release notes:\n",
      "     https://docs.aws.amazon.com/linux/al2023/release-notes/relnotes-2023.7.20250609.html\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Installed:\n",
      "  flac-libs-1.3.4-1.amzn2023.0.2.x86_64                                         \n",
      "  gsm-1.0.19-5.amzn2023.0.3.x86_64                                              \n",
      "  libogg-2:1.3.4-4.amzn2023.0.2.x86_64                                          \n",
      "  libsndfile-1.2.2-3.amzn2023.0.3.x86_64                                        \n",
      "  libvorbis-1:1.3.7-3.amzn2023.0.2.x86_64                                       \n",
      "  opus-1.3.1-8.amzn2023.0.3.x86_64                                              \n",
      "\n",
      "Complete!\n",
      "lrwxrwxrwx. 1 root root     20 Mar  4 02:13 /usr/lib64/libsndfile.so.1 -> libsndfile.so.1.0.37\n",
      "-rwxr-xr-x. 1 root root 534728 Mar  4 02:13 /usr/lib64/libsndfile.so.1.0.37\n"
     ]
    }
   ],
   "source": [
    "# Install libsndfile system dependency needed for fairseq2\n",
    "!sudo dnf install -y libsndfile\n",
    "\n",
    "# Verify that libsndfile is installed\n",
    "!ls -la /usr/lib64/libsndfile.so*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fc6a717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing fairseq2 for PyTorch 2.6.0 with cu124\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 4ms\u001b[0m\u001b[0m\n",
      "fairseq2 installation completed successfully!\n",
      "PyTorch version: 2.6.0+cu124\n",
      "PyTorch version: 2.6.0+cu124\n",
      "fairseq2 version: 0.4.6\n",
      "fairseq2 installation successful!\n",
      "fairseq2 version: 0.4.6\n",
      "fairseq2 installation successful!\n"
     ]
    }
   ],
   "source": [
    "# Install fairseq2 with the appropriate PyTorch version using our helper script\n",
    "# This script automatically detects your PyTorch version and installs the compatible fairseq2\n",
    "!python install_fairseq2.py\n",
    "\n",
    "# Verify PyTorch version\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Verify fairseq2 installation\n",
    "try:\n",
    "    import fairseq2\n",
    "    print(f\"fairseq2 version: {fairseq2.__version__}\")\n",
    "    print(\"fairseq2 installation successful!\")\n",
    "except ImportError:\n",
    "    print(\"fairseq2 not installed correctly. Please run the helper script again or install manually.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc9240d",
   "metadata": {},
   "source": [
    "## Setting Up BLASER 2.0\n",
    "\n",
    "Now, let's import the necessary modules and set up the BLASER 2.0 models. We'll use both the Quality Estimation (QE) model and the Reference-based model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4eb2086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "BLASER 2.0 models loaded successfully\n",
      "Text embedder initialized\n",
      "Text embedder initialized\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sonar.inference_pipelines.text import TextToEmbeddingModelPipeline\n",
    "from sonar.models.blaser.loader import load_blaser_model\n",
    "import torch\n",
    "\n",
    "# Set device based on availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load BLASER models\n",
    "try:\n",
    "    blaser_ref = load_blaser_model(\"blaser_2_0_ref\").eval().to(device)\n",
    "    blaser_qe = load_blaser_model(\"blaser_2_0_qe\").eval().to(device)\n",
    "    print(\"BLASER 2.0 models loaded successfully\")\n",
    "    \n",
    "    # Initialize text embedder\n",
    "    text_embedder = TextToEmbeddingModelPipeline(\n",
    "        encoder=\"text_sonar_basic_encoder\", \n",
    "        tokenizer=\"text_sonar_basic_encoder\",\n",
    "        device=device\n",
    "    )\n",
    "    print(\"Text embedder initialized\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading models: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90da0eda",
   "metadata": {},
   "source": [
    "## Testing Sentence Similarity with BLASER 2.0\n",
    "\n",
    "Let's test the sentence similarity functionality with some examples in different languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0874fef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source (French): Le chat s'assit sur le tapis.\n",
      "Reference (English): The cat sat on the mat.\n",
      "Machine Translation (English): The cat sat down on the carpet.\n",
      "\n",
      "BLASER 2.0 Similarity Scores (scale 1-5, higher is more similar):\n",
      "Reference-based score: 4.688\n",
      "Quality Estimation score: 4.708\n"
     ]
    }
   ],
   "source": [
    "# Example 1: French to English translation evaluation\n",
    "src_text = [\"Le chat s'assit sur le tapis.\"]\n",
    "ref_text = [\"The cat sat on the mat.\"]\n",
    "mt_text = [\"The cat sat down on the carpet.\"]\n",
    "\n",
    "print(\"Source (French):\", src_text[0])\n",
    "print(\"Reference (English):\", ref_text[0])\n",
    "print(\"Machine Translation (English):\", mt_text[0])\n",
    "\n",
    "# Get embeddings and move all to the same device\n",
    "src_embs = text_embedder.predict(src_text, source_lang=\"fra_Latn\").to(device)\n",
    "ref_embs = text_embedder.predict(ref_text, source_lang=\"eng_Latn\").to(device)\n",
    "mt_embs = text_embedder.predict(mt_text, source_lang=\"eng_Latn\").to(device)\n",
    "\n",
    "# Predict similarity scores\n",
    "with torch.inference_mode():\n",
    "    # Using reference-based model\n",
    "    ref_score = blaser_ref(src=src_embs, ref=ref_embs, mt=mt_embs).item()\n",
    "    \n",
    "    # Using quality estimation model (no reference)\n",
    "    qe_score = blaser_qe(src=src_embs, mt=mt_embs).item()\n",
    "\n",
    "print(\"\\nBLASER 2.0 Similarity Scores (scale 1-5, higher is more similar):\")\n",
    "print(f\"Reference-based score: {ref_score:.3f}\")\n",
    "print(f\"Quality Estimation score: {qe_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcefcad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Testing Multiple Language Pairs =====\n",
      "\n",
      "\n",
      "----- German to English -----\n",
      "Source (deu_Latn): Es ist ein schöner Tag heute.\n",
      "Reference (eng_Latn): It is a beautiful day today.\n",
      "Machine Translation (eng_Latn): It's a nice day today.\n",
      "Reference-based score: 4.761\n",
      "Quality Estimation score: 4.895\n",
      "\n",
      "----- Spanish to English -----\n",
      "Source (spa_Latn): El libro está sobre la mesa.\n",
      "Reference (eng_Latn): The book is on the table.\n",
      "Machine Translation (eng_Latn): A book is placed on the table.\n",
      "Reference-based score: 4.385\n",
      "Quality Estimation score: 4.303\n",
      "\n",
      "----- English to French -----\n",
      "Source (eng_Latn): I love studying languages.\n",
      "Reference (fra_Latn): J'adore étudier les langues.\n",
      "Machine Translation (fra_Latn): J'aime apprendre des langues.\n",
      "Reference-based score: 4.855\n",
      "Quality Estimation score: 5.026\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Testing with multiple language pairs\n",
    "language_examples = [\n",
    "    {\n",
    "        \"src\": [\"Es ist ein schöner Tag heute.\"], \n",
    "        \"src_lang\": \"deu_Latn\",\n",
    "        \"ref\": [\"It is a beautiful day today.\"],\n",
    "        \"ref_lang\": \"eng_Latn\",\n",
    "        \"mt\": [\"It's a nice day today.\"],\n",
    "        \"mt_lang\": \"eng_Latn\",\n",
    "        \"description\": \"German to English\"\n",
    "    },\n",
    "    {\n",
    "        \"src\": [\"El libro está sobre la mesa.\"], \n",
    "        \"src_lang\": \"spa_Latn\",\n",
    "        \"ref\": [\"The book is on the table.\"],\n",
    "        \"ref_lang\": \"eng_Latn\",\n",
    "        \"mt\": [\"A book is placed on the table.\"],\n",
    "        \"mt_lang\": \"eng_Latn\",\n",
    "        \"description\": \"Spanish to English\"\n",
    "    },\n",
    "    {\n",
    "        \"src\": [\"I love studying languages.\"], \n",
    "        \"src_lang\": \"eng_Latn\",\n",
    "        \"ref\": [\"J'adore étudier les langues.\"],\n",
    "        \"ref_lang\": \"fra_Latn\",\n",
    "        \"mt\": [\"J'aime apprendre des langues.\"],\n",
    "        \"mt_lang\": \"fra_Latn\",\n",
    "        \"description\": \"English to French\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\\n===== Testing Multiple Language Pairs =====\\n\")\n",
    "\n",
    "for example in language_examples:\n",
    "    print(f\"\\n----- {example['description']} -----\")\n",
    "    print(f\"Source ({example['src_lang']}): {example['src'][0]}\")\n",
    "    print(f\"Reference ({example['ref_lang']}): {example['ref'][0]}\")\n",
    "    print(f\"Machine Translation ({example['mt_lang']}): {example['mt'][0]}\")\n",
    "    \n",
    "    # Get embeddings and ensure they're on the same device\n",
    "    src_embs = text_embedder.predict(example['src'], source_lang=example['src_lang']).to(device)\n",
    "    ref_embs = text_embedder.predict(example['ref'], source_lang=example['ref_lang']).to(device)\n",
    "    mt_embs = text_embedder.predict(example['mt'], source_lang=example['mt_lang']).to(device)\n",
    "    \n",
    "    # Predict similarity scores\n",
    "    with torch.inference_mode():\n",
    "        ref_score = blaser_ref(src=src_embs, ref=ref_embs, mt=mt_embs).item()\n",
    "        qe_score = blaser_qe(src=src_embs, mt=mt_embs).item()\n",
    "        \n",
    "    print(f\"Reference-based score: {ref_score:.3f}\")\n",
    "    print(f\"Quality Estimation score: {qe_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2805b2",
   "metadata": {},
   "source": [
    "## Evaluating Translations of Varying Quality\n",
    "\n",
    "Let's test BLASER 2.0 with translations of varying quality to see how well it captures translation quality differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "665598f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Evaluating Translations of Varying Quality =====\n",
      "\n",
      "Source (English): This research paper presents a novel approach to natural language processing.\n",
      "\n",
      "High quality translation (fra_Latn): Cet article de recherche présente une approche novatrice du traitement du langage naturel.\n",
      "Quality Estimation score: 5.184\n",
      "\n",
      "Medium quality translation (fra_Latn): Ce papier de recherche présente une nouvelle approche pour le traitement du langage naturel.\n",
      "Quality Estimation score: 5.124\n",
      "\n",
      "Low quality translation (fra_Latn): Ce document recherche montre nouveau façon pour traitement langue naturelle.\n",
      "Quality Estimation score: 4.568\n",
      "\n",
      "Unrelated content translation (fra_Latn): Ce texte parle de cuisine française et de recettes traditionnelles.\n",
      "Quality Estimation score: 3.170\n"
     ]
    }
   ],
   "source": [
    "# Example 3: Translations of varying quality\n",
    "source = [\"This research paper presents a novel approach to natural language processing.\"]\n",
    "source_lang = \"eng_Latn\"\n",
    "\n",
    "translations = [\n",
    "    {\n",
    "        \"text\": [\"Cet article de recherche présente une approche novatrice du traitement du langage naturel.\"],\n",
    "        \"lang\": \"fra_Latn\",\n",
    "        \"quality\": \"High quality\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": [\"Ce papier de recherche présente une nouvelle approche pour le traitement du langage naturel.\"],\n",
    "        \"lang\": \"fra_Latn\",\n",
    "        \"quality\": \"Medium quality\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": [\"Ce document recherche montre nouveau façon pour traitement langue naturelle.\"],\n",
    "        \"lang\": \"fra_Latn\",\n",
    "        \"quality\": \"Low quality\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": [\"Ce texte parle de cuisine française et de recettes traditionnelles.\"],\n",
    "        \"lang\": \"fra_Latn\",\n",
    "        \"quality\": \"Unrelated content\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"\\n===== Evaluating Translations of Varying Quality =====\\n\")\n",
    "print(f\"Source (English): {source[0]}\")\n",
    "\n",
    "# Get source embedding and ensure it's on the correct device\n",
    "src_embs = text_embedder.predict(source, source_lang=source_lang).to(device)\n",
    "\n",
    "# Evaluate each translation\n",
    "for translation in translations:\n",
    "    print(f\"\\n{translation['quality']} translation ({translation['lang']}): {translation['text'][0]}\")\n",
    "    \n",
    "    # Get translation embedding and ensure it's on the same device\n",
    "    mt_embs = text_embedder.predict(translation['text'], source_lang=translation['lang']).to(device)\n",
    "    \n",
    "    # Predict quality estimation score\n",
    "    with torch.inference_mode():\n",
    "        qe_score = blaser_qe(src=src_embs, mt=mt_embs).item()\n",
    "        \n",
    "    print(f\"Quality Estimation score: {qe_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4f958b",
   "metadata": {},
   "source": [
    "## Interactive Text Similarity Evaluation\n",
    "\n",
    "The following cell allows you to input custom text for similarity evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9be374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check ipywidgets installation and enable the extension\n",
    "try:\n",
    "    import ipywidgets\n",
    "    print(f\"ipywidgets version: {ipywidgets.__version__}\")\n",
    "    \n",
    "    # Enable the extension\n",
    "    from IPython import get_ipython\n",
    "    if get_ipython() is not None:\n",
    "        get_ipython().run_line_magic('load_ext', 'ipywidgets')\n",
    "        print(\"ipywidgets extension loaded successfully\")\n",
    "    else:\n",
    "        print(\"Not running in an IPython environment\")\n",
    "    \n",
    "    # Verify that the widgets are properly registered\n",
    "    print(\"Available widget models:\", ipywidgets.Widget.widget_types)\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"ipywidgets not properly installed: {e}\")\n",
    "    print(\"Installing ipywidgets...\")\n",
    "    %pip install ipywidgets\n",
    "    print(\"Please restart the kernel after installation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64549f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c419dce2e2654f0d9da2a08909815c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='eng_Latn', description='Source Lang:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b45aa0052248ea829c3efe32f6a5ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='The weather is nice today.', description='Source Text:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e406da8da26d48c5938e165ff5d22de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='fra_Latn', description='Trans Lang:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebeab563db5a4f03bbc64f0b6b73760e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value=\"Le temps est beau aujourd'hui.\", description='Translation:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4d4d2b8ab84804b5d35689e903b9b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Evaluate Similarity', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Custom text input\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Initialize Jupyter widgets extension if not already initialized\n",
    "from IPython import get_ipython\n",
    "if get_ipython() is not None:\n",
    "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "    # Make sure widgets are properly initialized\n",
    "    get_ipython().run_line_magic('reload_ext', 'ipywidgets')\n",
    "    \n",
    "# Create input widgets\n",
    "src_lang_input = widgets.Text(value='eng_Latn', description='Source Lang:', layout={'width': '300px'})\n",
    "src_text_input = widgets.Textarea(value='The weather is nice today.', description='Source Text:', layout={'width': '500px'})\n",
    "mt_lang_input = widgets.Text(value='fra_Latn', description='Trans Lang:', layout={'width': '300px'})\n",
    "mt_text_input = widgets.Textarea(value='Le temps est beau aujourd\\'hui.', description='Translation:', layout={'width': '500px'})\n",
    "\n",
    "# Function to evaluate similarity\n",
    "def evaluate_similarity(button):\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    # Display inputs\n",
    "    display(src_lang_input, src_text_input, mt_lang_input, mt_text_input, evaluate_button)\n",
    "    \n",
    "    print(\"\\nEvaluating similarity...\\n\")\n",
    "    \n",
    "    src_text = [src_text_input.value]\n",
    "    mt_text = [mt_text_input.value]\n",
    "    src_lang = src_lang_input.value\n",
    "    mt_lang = mt_lang_input.value\n",
    "    \n",
    "    try:\n",
    "        # Get embeddings and ensure they're on the same device\n",
    "        src_embs = text_embedder.predict(src_text, source_lang=src_lang).to(device)\n",
    "        mt_embs = text_embedder.predict(mt_text, source_lang=mt_lang).to(device)\n",
    "        \n",
    "        # Predict similarity score\n",
    "        with torch.inference_mode():\n",
    "            qe_score = blaser_qe(src=src_embs, mt=mt_embs).item()\n",
    "            \n",
    "        print(f\"Source ({src_lang}): {src_text[0]}\")\n",
    "        print(f\"Translation ({mt_lang}): {mt_text[0]}\")\n",
    "        print(f\"\\nQuality Estimation score: {qe_score:.3f} (scale: 1-5, higher is more similar)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Create evaluate button with callback\n",
    "evaluate_button = widgets.Button(description=\"Evaluate Similarity\", button_style='primary')\n",
    "evaluate_button.on_click(evaluate_similarity)\n",
    "\n",
    "# Group widgets in a vertical box for better layout\n",
    "widget_box = widgets.VBox([\n",
    "    widgets.HBox([src_lang_input]),\n",
    "    src_text_input,\n",
    "    widgets.HBox([mt_lang_input]),\n",
    "    mt_text_input,\n",
    "    evaluate_button\n",
    "])\n",
    "\n",
    "# Display widgets\n",
    "display(widget_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0454e6",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "BLASER 2.0 provides a powerful way to evaluate translation quality and sentence similarity across languages using the SONAR embedding space. It can be used in various scenarios:\n",
    "\n",
    "- Machine translation quality evaluation\n",
    "- Cross-lingual similarity assessment\n",
    "- Comparing translation alternatives\n",
    "- Evaluating speech-to-text translations\n",
    "\n",
    "For more information, visit:\n",
    "- [SONAR GitHub Repository](https://github.com/facebookresearch/SONAR)\n",
    "- [BLASER 2.0 QE Model Card](https://huggingface.co/facebook/blaser-2.0-qe)\n",
    "- [BLASER 2.0 Ref Model Card](https://huggingface.co/facebook/blaser-2.0-ref)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
