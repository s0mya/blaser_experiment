{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaf69fc4",
   "metadata": {},
   "source": [
    "# BLASER 2.0: Testing Sentence Similarity\n",
    "\n",
    "This notebook demonstrates how to use BLASER 2.0 for predicting sentence similarity using the SONAR embedding space. BLASER 2.0 is a family of models for automatic evaluation of machine translation quality based on SONAR embeddings.\n",
    "\n",
    "There are two main models available:\n",
    "- **BLASER 2.0 QE (Quality Estimation)**: Predicts similarity between source text and translation without requiring reference translations\n",
    "- **BLASER 2.0 Ref**: Predicts similarity using source, translation, and reference translation\n",
    "\n",
    "Both models are based on the [SONAR](https://github.com/facebookresearch/SONAR) (Sentence-level multimOdal and laNguage-Agnostic Representations) framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb6a5f6",
   "metadata": {},
   "source": [
    "## Installing Required Packages with UV\n",
    "\n",
    "We'll use `uv` to create a virtual environment and install the necessary packages. UV is a fast Python package installer and resolver, which makes dependency management more efficient.\n",
    "\n",
    "SONAR requires specific versions of fairseq2 that match the PyTorch and CUDA versions. If you don't have `uv` installed, you can install it first with:\n",
    "```bash\n",
    "curl -sSf https://install.python-uv.org | python3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb70c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and activate environment with uv using pyproject.toml\n",
    "!uv venv create .venv\n",
    "!source .venv/bin/activate\n",
    "\n",
    "# Install the project and its dependencies from pyproject.toml\n",
    "!uv pip install -e .\n",
    "\n",
    "# Check if UV installation was successful\n",
    "!uv --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc6a717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install fairseq2 with the appropriate PyTorch version using our helper script\n",
    "# This script automatically detects your PyTorch version and installs the compatible fairseq2\n",
    "!python install_fairseq2.py\n",
    "\n",
    "# Verify PyTorch version\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Verify fairseq2 installation\n",
    "try:\n",
    "    import fairseq2\n",
    "    print(f\"fairseq2 version: {fairseq2.__version__}\")\n",
    "    print(\"fairseq2 installation successful!\")\n",
    "except ImportError:\n",
    "    print(\"fairseq2 not installed correctly. Please run the helper script again or install manually.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc9240d",
   "metadata": {},
   "source": [
    "## Setting Up BLASER 2.0\n",
    "\n",
    "Now, let's import the necessary modules and set up the BLASER 2.0 models. We'll use both the Quality Estimation (QE) model and the Reference-based model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eb2086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sonar.inference_pipelines.text import TextToEmbeddingModelPipeline\n",
    "from sonar.models.blaser.loader import load_blaser_model\n",
    "import torch\n",
    "\n",
    "# Set device based on availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load BLASER models\n",
    "try:\n",
    "    blaser_ref = load_blaser_model(\"blaser_2_0_ref\").eval()\n",
    "    blaser_qe = load_blaser_model(\"blaser_2_0_qe\").eval()\n",
    "    print(\"BLASER 2.0 models loaded successfully\")\n",
    "    \n",
    "    # Initialize text embedder\n",
    "    text_embedder = TextToEmbeddingModelPipeline(\n",
    "        encoder=\"text_sonar_basic_encoder\", \n",
    "        tokenizer=\"text_sonar_basic_encoder\",\n",
    "        device=device\n",
    "    )\n",
    "    print(\"Text embedder initialized\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading models: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90da0eda",
   "metadata": {},
   "source": [
    "## Testing Sentence Similarity with BLASER 2.0\n",
    "\n",
    "Let's test the sentence similarity functionality with some examples in different languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0874fef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: French to English translation evaluation\n",
    "src_text = [\"Le chat s'assit sur le tapis.\"]\n",
    "ref_text = [\"The cat sat on the mat.\"]\n",
    "mt_text = [\"The cat sat down on the carpet.\"]\n",
    "\n",
    "print(\"Source (French):\", src_text[0])\n",
    "print(\"Reference (English):\", ref_text[0])\n",
    "print(\"Machine Translation (English):\", mt_text[0])\n",
    "\n",
    "# Get embeddings\n",
    "src_embs = text_embedder.predict(src_text, source_lang=\"fra_Latn\")\n",
    "ref_embs = text_embedder.predict(ref_text, source_lang=\"eng_Latn\")\n",
    "mt_embs = text_embedder.predict(mt_text, source_lang=\"eng_Latn\")\n",
    "\n",
    "# Predict similarity scores\n",
    "with torch.inference_mode():\n",
    "    # Using reference-based model\n",
    "    ref_score = blaser_ref(src=src_embs, ref=ref_embs, mt=mt_embs).item()\n",
    "    \n",
    "    # Using quality estimation model (no reference)\n",
    "    qe_score = blaser_qe(src=src_embs, mt=mt_embs).item()\n",
    "\n",
    "print(\"\\nBLASER 2.0 Similarity Scores (scale 1-5, higher is more similar):\")\n",
    "print(f\"Reference-based score: {ref_score:.3f}\")\n",
    "print(f\"Quality Estimation score: {qe_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcefcad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Testing with multiple language pairs\n",
    "language_examples = [\n",
    "    {\n",
    "        \"src\": [\"Es ist ein schöner Tag heute.\"], \n",
    "        \"src_lang\": \"deu_Latn\",\n",
    "        \"ref\": [\"It is a beautiful day today.\"],\n",
    "        \"ref_lang\": \"eng_Latn\",\n",
    "        \"mt\": [\"It's a nice day today.\"],\n",
    "        \"mt_lang\": \"eng_Latn\",\n",
    "        \"description\": \"German to English\"\n",
    "    },\n",
    "    {\n",
    "        \"src\": [\"El libro está sobre la mesa.\"], \n",
    "        \"src_lang\": \"spa_Latn\",\n",
    "        \"ref\": [\"The book is on the table.\"],\n",
    "        \"ref_lang\": \"eng_Latn\",\n",
    "        \"mt\": [\"A book is placed on the table.\"],\n",
    "        \"mt_lang\": \"eng_Latn\",\n",
    "        \"description\": \"Spanish to English\"\n",
    "    },\n",
    "    {\n",
    "        \"src\": [\"I love studying languages.\"], \n",
    "        \"src_lang\": \"eng_Latn\",\n",
    "        \"ref\": [\"J'adore étudier les langues.\"],\n",
    "        \"ref_lang\": \"fra_Latn\",\n",
    "        \"mt\": [\"J'aime apprendre des langues.\"],\n",
    "        \"mt_lang\": \"fra_Latn\",\n",
    "        \"description\": \"English to French\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\\n===== Testing Multiple Language Pairs =====\\n\")\n",
    "\n",
    "for example in language_examples:\n",
    "    print(f\"\\n----- {example['description']} -----\")\n",
    "    print(f\"Source ({example['src_lang']}): {example['src'][0]}\")\n",
    "    print(f\"Reference ({example['ref_lang']}): {example['ref'][0]}\")\n",
    "    print(f\"Machine Translation ({example['mt_lang']}): {example['mt'][0]}\")\n",
    "    \n",
    "    # Get embeddings\n",
    "    src_embs = text_embedder.predict(example['src'], source_lang=example['src_lang'])\n",
    "    ref_embs = text_embedder.predict(example['ref'], source_lang=example['ref_lang'])\n",
    "    mt_embs = text_embedder.predict(example['mt'], source_lang=example['mt_lang'])\n",
    "    \n",
    "    # Predict similarity scores\n",
    "    with torch.inference_mode():\n",
    "        ref_score = blaser_ref(src=src_embs, ref=ref_embs, mt=mt_embs).item()\n",
    "        qe_score = blaser_qe(src=src_embs, mt=mt_embs).item()\n",
    "        \n",
    "    print(f\"Reference-based score: {ref_score:.3f}\")\n",
    "    print(f\"Quality Estimation score: {qe_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2805b2",
   "metadata": {},
   "source": [
    "## Evaluating Translations of Varying Quality\n",
    "\n",
    "Let's test BLASER 2.0 with translations of varying quality to see how well it captures translation quality differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665598f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Translations of varying quality\n",
    "source = [\"This research paper presents a novel approach to natural language processing.\"]\n",
    "source_lang = \"eng_Latn\"\n",
    "\n",
    "translations = [\n",
    "    {\n",
    "        \"text\": [\"Cet article de recherche présente une approche novatrice du traitement du langage naturel.\"],\n",
    "        \"lang\": \"fra_Latn\",\n",
    "        \"quality\": \"High quality\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": [\"Ce papier de recherche présente une nouvelle approche pour le traitement du langage naturel.\"],\n",
    "        \"lang\": \"fra_Latn\",\n",
    "        \"quality\": \"Medium quality\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": [\"Ce document recherche montre nouveau façon pour traitement langue naturelle.\"],\n",
    "        \"lang\": \"fra_Latn\",\n",
    "        \"quality\": \"Low quality\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": [\"Ce texte parle de cuisine française et de recettes traditionnelles.\"],\n",
    "        \"lang\": \"fra_Latn\",\n",
    "        \"quality\": \"Unrelated content\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"\\n===== Evaluating Translations of Varying Quality =====\\n\")\n",
    "print(f\"Source (English): {source[0]}\")\n",
    "\n",
    "# Get source embedding\n",
    "src_embs = text_embedder.predict(source, source_lang=source_lang)\n",
    "\n",
    "# Evaluate each translation\n",
    "for translation in translations:\n",
    "    print(f\"\\n{translation['quality']} translation ({translation['lang']}): {translation['text'][0]}\")\n",
    "    \n",
    "    # Get translation embedding\n",
    "    mt_embs = text_embedder.predict(translation['text'], source_lang=translation['lang'])\n",
    "    \n",
    "    # Predict quality estimation score\n",
    "    with torch.inference_mode():\n",
    "        qe_score = blaser_qe(src=src_embs, mt=mt_embs).item()\n",
    "        \n",
    "    print(f\"Quality Estimation score: {qe_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4f958b",
   "metadata": {},
   "source": [
    "## Interactive Text Similarity Evaluation\n",
    "\n",
    "The following cell allows you to input custom text for similarity evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64549f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom text input\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Create input widgets\n",
    "src_lang_input = widgets.Text(value='eng_Latn', description='Source Lang:')\n",
    "src_text_input = widgets.Textarea(value='The weather is nice today.', description='Source Text:')\n",
    "mt_lang_input = widgets.Text(value='fra_Latn', description='Trans Lang:')\n",
    "mt_text_input = widgets.Textarea(value='Le temps est beau aujourd\\'hui.', description='Translation:')\n",
    "\n",
    "# Function to evaluate similarity\n",
    "def evaluate_similarity(button):\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    # Display inputs\n",
    "    display(src_lang_input, src_text_input, mt_lang_input, mt_text_input, evaluate_button)\n",
    "    \n",
    "    print(\"\\nEvaluating similarity...\\n\")\n",
    "    \n",
    "    src_text = [src_text_input.value]\n",
    "    mt_text = [mt_text_input.value]\n",
    "    src_lang = src_lang_input.value\n",
    "    mt_lang = mt_lang_input.value\n",
    "    \n",
    "    try:\n",
    "        # Get embeddings\n",
    "        src_embs = text_embedder.predict(src_text, source_lang=src_lang)\n",
    "        mt_embs = text_embedder.predict(mt_text, source_lang=mt_lang)\n",
    "        \n",
    "        # Predict similarity score\n",
    "        with torch.inference_mode():\n",
    "            qe_score = blaser_qe(src=src_embs, mt=mt_embs).item()\n",
    "            \n",
    "        print(f\"Source ({src_lang}): {src_text[0]}\")\n",
    "        print(f\"Translation ({mt_lang}): {mt_text[0]}\")\n",
    "        print(f\"\\nQuality Estimation score: {qe_score:.3f} (scale: 1-5, higher is more similar)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Create evaluate button with callback\n",
    "evaluate_button = widgets.Button(description=\"Evaluate Similarity\")\n",
    "evaluate_button.on_click(evaluate_similarity)\n",
    "\n",
    "# Display widgets\n",
    "display(src_lang_input, src_text_input, mt_lang_input, mt_text_input, evaluate_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0454e6",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "BLASER 2.0 provides a powerful way to evaluate translation quality and sentence similarity across languages using the SONAR embedding space. It can be used in various scenarios:\n",
    "\n",
    "- Machine translation quality evaluation\n",
    "- Cross-lingual similarity assessment\n",
    "- Comparing translation alternatives\n",
    "- Evaluating speech-to-text translations\n",
    "\n",
    "For more information, visit:\n",
    "- [SONAR GitHub Repository](https://github.com/facebookresearch/SONAR)\n",
    "- [BLASER 2.0 QE Model Card](https://huggingface.co/facebook/blaser-2.0-qe)\n",
    "- [BLASER 2.0 Ref Model Card](https://huggingface.co/facebook/blaser-2.0-ref)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
